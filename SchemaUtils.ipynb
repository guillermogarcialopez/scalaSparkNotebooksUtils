{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4611af56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.132:4040\n",
       "SparkContext available as 'sc' (version = 3.5.0, master = local[*], app id = local-1699855239979)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\r\n"
     ]
    }
   ],
   "source": [
    "println(\"================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b90726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.collection.mutable\r\n",
       "import scala.util.Try\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "import org.apache.spark.sql.DataFrame\r\n",
       "import org.apache.spark.sql.Column\r\n",
       "import org.apache.spark.sql.types._\r\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable\n",
    "import scala.util.Try\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.Column\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb98240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isWindows: Boolean\r\n",
       "isLinux: Boolean\r\n",
       "printOS: Unit\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TODO FIX RUN NB INTO ANOTHER\n",
    "//%run ./OSUtils.ipynb\n",
    "\n",
    "def isWindows: Boolean = System.getProperty(\"os.name\").toUpperCase.contains(\"WINDOWS\")\n",
    "def isLinux: Boolean = System.getProperty(\"os.name\").toUpperCase.contains(\"LINUX\")\n",
    "\n",
    "def printOS: Unit =    \n",
    "    if (isWindows) println(\"THIS IS A WINDOWS OS\")\n",
    "    else println(\"THIS IS A LINUX OS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef10580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfFlights: org.apache.spark.sql.DataFrame = [DayofMonth: string, DayOfWeek: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfFlights = spark.read.option(\"header\", true).csv(\"./data/flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80692347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- OriginAirportID: string (nullable = true)\n",
      " |-- DestAirportID: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dfFlights.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd4ddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schemaContainsField: (schema: List[String], fieldsToCheck: List[String])Unit\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/** Check if schema from a df contains some values.\n",
    "  * @param schema: Df schema\n",
    "  * @param fieldsToCheck: List of columns to check\n",
    "  * @return: Unit\n",
    "  */\n",
    "def schemaContainsField(schema: List[String], fieldsToCheck: List[String]): Unit = {\n",
    "    fieldsToCheck.foreach(f => {\n",
    "        if (schema.contains(f)) println(s\"$f --> true\")\n",
    "        else println(s\"$f --> false\")})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01836480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fieldsToCheck: List[String] = List(DayofMonth, Carrier, carrier)\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fieldsToCheck: List[String] = List(\"DayofMonth\", \"Carrier\", \"carrier\") // Case sensitive!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6be402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DayofMonth --> true\n",
      "Carrier --> true\n",
      "carrier --> false\n"
     ]
    }
   ],
   "source": [
    "schemaContainsField(dfFlights.schema.names.toList, fieldsToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3590eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hasColumn: (df: org.apache.spark.sql.DataFrame, column: String)Boolean\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/** Check if df has single column\n",
    "  * @param df: DataFrame\n",
    "  * @param column:Column to check\n",
    "  * @return: Boolean if df has column\n",
    "*/\n",
    "def hasColumn(df: DataFrame, column: String): Boolean = Try(df(column)).isSuccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "787ccc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Boolean = true\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasColumn(dfFlights, \"DayOfWeek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8791a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Boolean = false\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasColumn(dfFlights, \"Aeroport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d65138c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addSufixColumns: (df: org.apache.spark.sql.DataFrame, suf: String)org.apache.spark.sql.DataFrame\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addSufixColumns(df: DataFrame, suf: String): DataFrame = {\n",
    "    val origColumns = df.columns\n",
    "    val colsRenamed = origColumns.map {_ + suf}\n",
    "    df.toDF(colsRenamed:_*)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1be5aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newDf: org.apache.spark.sql.DataFrame = [DayofMonth_FLGHTS: string, DayOfWeek_FLGHTS: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newDf = addSufixColumns(dfFlights, \"_FLGHTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50db9272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth_FLGHTS: string (nullable = true)\n",
      " |-- DayOfWeek_FLGHTS: string (nullable = true)\n",
      " |-- Carrier_FLGHTS: string (nullable = true)\n",
      " |-- OriginAirportID_FLGHTS: string (nullable = true)\n",
      " |-- DestAirportID_FLGHTS: string (nullable = true)\n",
      " |-- DepDelay_FLGHTS: string (nullable = true)\n",
      " |-- ArrDelay_FLGHTS: string (nullable = true)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "newDf.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36454a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addColumn: (df: org.apache.spark.sql.DataFrame, col: (String, org.apache.spark.sql.Column)*)org.apache.spark.sql.DataFrame\r\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "   * Add columns to dataframe\n",
    "   * @param df dataframe\n",
    "   * @param col pair of name and column (name,column)\n",
    "   * @return df with new columns\n",
    "   */\n",
    "def addColumn(df: DataFrame, col: (String, Column)*): DataFrame =\n",
    "    col.foldLeft(df) { case (dfbase, (name, col)) => dfbase.withColumn(name, col) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dab49fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfAdded: org.apache.spark.sql.DataFrame = [DayofMonth: string, DayOfWeek: string ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfAdded = addColumn(dfFlights, (\"LITERAL\", lit(\"XXX\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c018819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- OriginAirportID: string (nullable = true)\n",
      " |-- DestAirportID: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- LITERAL: string (nullable = false)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dfAdded.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "729d67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+-------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|LITERAL|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+-------+\n",
      "|19        |5        |DL     |11433          |13303        |-3      |1       |XXX    |\n",
      "|19        |5        |DL     |14869          |12478        |0       |-8      |XXX    |\n",
      "|19        |5        |DL     |14057          |14869        |-4      |-15     |XXX    |\n",
      "|19        |5        |DL     |15016          |11433        |28      |24      |XXX    |\n",
      "|19        |5        |DL     |11193          |12892        |-6      |-11     |XXX    |\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dfAdded.show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbd94933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findDuplicateRows: (df: org.apache.spark.sql.DataFrame, columns: Seq[String])org.apache.spark.sql.DataFrame\r\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "    *\n",
    "    * @param df\n",
    "    * @param columns\n",
    "    * @return\n",
    "    */\n",
    "def findDuplicateRows(df: DataFrame, columns: Seq[String]): DataFrame = {\n",
    "  df.groupBy(columns.head,columns.tail:_*)\n",
    "    .agg(count(\"*\").alias(\"cnt\"))\n",
    "    .filter(col(\"cnt\") > 1)\n",
    "    .select(columns.map(col): _*)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a7c58bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        11|        4|     AA|          13930|        12953|       0|       0|\n",
      "|        17|        3|     MQ|          12451|        13303|       0|       0|\n",
      "|        21|        7|     OO|          14831|        12892|       0|       0|\n",
      "|        23|        2|     EV|          11618|        10693|       0|       0|\n",
      "|         4|        4|     AA|          11298|        13495|       0|       0|\n",
      "|        11|        4|     AA|          13930|        14747|       0|       0|\n",
      "|        11|        4|     MQ|          11193|        13930|       0|       0|\n",
      "|        16|        2|     AA|          10721|        11298|       0|       0|\n",
      "|        16|        2|     AA|          14869|        11298|       0|       0|\n",
      "|        17|        3|     EV|          13931|        13930|       0|       0|\n",
      "|        17|        3|     OO|          13487|        13930|       0|       0|\n",
      "|        18|        4|     AA|          13204|        11298|       0|       0|\n",
      "|        18|        4|     MQ|          11298|        14730|       0|       0|\n",
      "|        18|        4|     MQ|          13930|        10821|       0|       0|\n",
      "|        22|        1|     EV|          13487|        11618|       0|       0|\n",
      "|        23|        2|     US|          12953|        11278|       0|       0|\n",
      "|        23|        2|     WN|          11259|        12191|       0|       0|\n",
      "|         7|        7|     MQ|          14492|        12953|       0|       0|\n",
      "|        16|        2|     AA|          13303|        13204|       0|       0|\n",
      "|        18|        4|     AA|          13930|        11298|       0|       0|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "findDuplicateRows(dfFlights, dfFlights.schema.names.toSeq).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14405196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stringify: (c: org.apache.spark.sql.Column)org.apache.spark.sql.Column\r\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "*\n",
    "* @param c\n",
    "* @return\n",
    "*/\n",
    "def stringify(c: Column) = concat(lit(\"[\"), concat_ws(\",\", c), lit(\"]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51beb367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfStringify: org.apache.spark.sql.DataFrame = [DayofMonth: string, DayOfWeek: string ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfStringify = dfFlights.withColumn(\"colStringified\", stringify(dfFlights.col(\"DayofMonth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12e3eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|colStringified|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|          [19]|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|          [19]|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|          [19]|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|          [19]|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|          [19]|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|          [19]|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|          [19]|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|          [19]|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|          [19]|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|          [19]|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|          [19]|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|          [19]|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|          [19]|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|          [19]|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|          [19]|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|          [19]|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|          [19]|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|          [19]|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|          [19]|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|          [19]|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dfStringify.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a23aff1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schemaArr: Array[org.apache.spark.sql.types.StructField] = Array(StructField(DayofMonth,StringType,true), StructField(DayOfWeek,StringType,true), StructField(Carrier,StringType,true), StructField(OriginAirportID,StringType,true), StructField(DestAirportID,StringType,true), StructField(DepDelay,StringType,true), StructField(ArrDelay,StringType,true))\r\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schemaArr = dfFlights.schema.toArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e29fa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res21: org.apache.spark.sql.types.StructField = StructField(DayOfWeek,StringType,true)\r\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaArr(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d85c50d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class STFieldCC\r\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class STFieldCC(colName: String, field: StructField)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9396e8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checkIfSameSchema: (df1: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame)Boolean\r\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkIfSameSchema(df1: DataFrame, df2: DataFrame): Boolean = df1.schema.equals(df2.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c348c459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- OriginAirportID: string (nullable = true)\n",
      " |-- DestAirportID: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dfFlights.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c8cb622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfFlightsLong: org.apache.spark.sql.DataFrame = [DayofMonth: string, DayOfWeek: string ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfFlightsLong = dfFlights.withColumn(\"LONG_COL\", lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd8061e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- OriginAirportID: string (nullable = true)\n",
      " |-- DestAirportID: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- LONG_COL: integer (nullable = false)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dfFlightsLong.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ea80496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "castColumnTo: (df: org.apache.spark.sql.DataFrame, fieldName: String, dataType: org.apache.spark.sql.types.DataType)org.apache.spark.sql.DataFrame\r\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "    *\n",
    "    * @param df\n",
    "    * @param fieldName\n",
    "    * @param dataType\n",
    "    * @return\n",
    "    */\n",
    "def castColumnTo(df: DataFrame, fieldName: String, dataType: DataType ) : DataFrame = \n",
    "    df.withColumn( fieldName, df(fieldName).cast(dataType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95179792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfFlightsString: org.apache.spark.sql.DataFrame = [DayofMonth: string, DayOfWeek: string ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfFlightsString = castColumnTo(dfFlightsLong, \"LONG_COL\", StringType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51687ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- OriginAirportID: string (nullable = true)\n",
      " |-- DestAirportID: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- LONG_COL: string (nullable = false)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dfFlightsString.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd3c085a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: Boolean = false\r\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkIfSameSchema(dfFlightsLong, dfFlightsString)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
