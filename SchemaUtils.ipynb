{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4611af56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.132:4040\n",
       "SparkContext available as 'sc' (version = 3.5.0, master = local[*], app id = local-1699630617671)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\r\n"
     ]
    }
   ],
   "source": [
    "println(\"================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b90726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.collection.mutable\r\n",
       "import scala.util.Try\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "import org.apache.spark.sql.DataFrame\r\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable\n",
    "import scala.util.Try\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fb98240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isWindows: Boolean\r\n",
       "isLinux: Boolean\r\n",
       "printOS: Unit\r\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TODO FIX RUN NB INTO ANOTHER\n",
    "//%run ./OSUtils.ipynb\n",
    "\n",
    "def isWindows: Boolean = System.getProperty(\"os.name\").toUpperCase.contains(\"WINDOWS\")\n",
    "def isLinux: Boolean = System.getProperty(\"os.name\").toUpperCase.contains(\"LINUX\")\n",
    "\n",
    "def printOS: Unit =    \n",
    "    if (isWindows) println(\"THIS IS A WINDOWS OS\")\n",
    "    else println(\"THIS IS A LINUX OS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ef10580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfFlights: org.apache.spark.sql.DataFrame = [DayofMonth: string, DayOfWeek: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfFlights = spark.read.option(\"header\", true).csv(\"./data/flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80692347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- OriginAirportID: string (nullable = true)\n",
      " |-- DestAirportID: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dfFlights.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bd4ddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schemaContainsField: (schema: List[String], fieldsToCheck: List[String])Unit\r\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/** Check if schema from a df contains some values.\n",
    "  * @param schema: Df schema\n",
    "  * @param fieldsToCheck: List of columns to check\n",
    "  * @return: Unit\n",
    "  */\n",
    "def schemaContainsField(schema: List[String], fieldsToCheck: List[String]): Unit = {\n",
    "    fieldsToCheck.foreach(f => {\n",
    "        if (schema.contains(f)) println(s\"$f --> true\")\n",
    "        else println(s\"$f --> false\")})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01836480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fieldsToCheck: List[String] = List(DayofMonth, Carrier, carrier)\r\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fieldsToCheck: List[String] = List(\"DayofMonth\", \"Carrier\", \"carrier\") // Case sensitive!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff6be402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DayofMonth --> true\n",
      "Carrier --> true\n",
      "carrier --> false\n"
     ]
    }
   ],
   "source": [
    "schemaContainsField(dfFlights.schema.names.toList, fieldsToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf3590eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hasColumn: (df: org.apache.spark.sql.DataFrame, column: String)Boolean\r\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/** Check if df has single column\n",
    "  * @param df: DataFrame\n",
    "  * @param column:Column to check\n",
    "  * @return: Boolean if df has column\n",
    "*/\n",
    "def hasColumn(df: DataFrame, column: String): Boolean = Try(df(column)).isSuccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "787ccc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res28: Boolean = true\r\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasColumn(dfFlights, \"DayOfWeek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8791a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res26: Boolean = false\r\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasColumn(dfFlights, \"Aeroport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65138c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
